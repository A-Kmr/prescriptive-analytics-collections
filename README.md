# ğŸ’° Prescriptive Analytics for Collections Optimization

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-App-FF4B4B.svg)
![Optimization](https://img.shields.io/badge/Optimization-Linear%20Programming-success)

> **Business Impact:** Demonstrated a **27.1% uplift** in daily recoverable revenue by shifting from a traditional "Risk-Based" strategy to a "Value-Based" Prescriptive Analytics engine.

## ğŸ“Œ Executive Summary
In financial collections, call center capacity is a hard constraint (e.g., 50 calls/day). Traditional strategies prioritize accounts with the highest **Probability of Default (PD)**. This approach often leads to inefficient resource allocationâ€”agents spend time chasing low-balance accounts simply because they are "risky," while missing high-value opportunities.

This project implements a **Prescriptive Analytics Engine** that optimizes resource allocation. By combining **Credit Risk Modeling** (PD/LGD/EAD framework) with **Mathematical Optimization** (Linear Programming), the model identifies the specific set of accounts that maximizes **Expected Recovery** under strict capacity constraints.

---
## ğŸ“ Project Structure

```bash
collections-optimization/
â”œâ”€â”€ generate_data.py    # Synthetic dataset generation
â”œâ”€â”€ train_model.py      # PD/LGD model training
â”œâ”€â”€ optimize.py         # Linear Programming solver
â”œâ”€â”€ app.py              # Streamlit dashboard
â”œâ”€â”€ invoices.csv        # Generated invoice data
â”œâ”€â”€ modeled_data.csv    # Data with predicted risk scores
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ README.md           # This file
â””â”€â”€ strategy_comparison.png  # Visualization output
```
---

## ğŸ“Š Key Results

The optimization engine was tested against two baseline strategies on a synthetic dataset of 10,000 invoices with a daily capacity of 50 calls.

| Strategy | Logic | Daily Recovery ($) | Performance vs Naive |
|----------|-------|--------------------|----------------------|
| **Random** | Random Selection | ~$7,160 | -76% |
| **Naive (Baseline)** | Highest Risk (PD) First | ~$30,700 | Baseline |
| **ML + Optimization** | **Maximize Expected Value** | **~$39,000** | **+27.1% ğŸš€** |

---

## ğŸ¯ Credit Risk Framework

This project implements the industry-standard credit risk calculation to determine the **Expected Value** of a collection call:

$$\text{Expected Recovery} = \text{EAD} \times \text{PD} \times \text{LGD} \times \text{Intervention Effect}$$

Where:
* **PD (Probability of Default):** The likelihood the customer will not pay (Predicted via XGBoost/Random Forest).
* **EAD (Exposure at Default):** The outstanding invoice amount (Current Balance).
* **LGD (Loss Given Default):** The percentage of the debt lost if a default occurs (Predicted or Assumed).
* **Intervention Effect:** The probability lift generated by a phone call (e.g., calling reduces default risk by 30%).

**The Shift:**
* **Traditional:** Sort by $PD$ (Risk only).
* **Optimized:** Sort by $EAD \times PD \times LGD$ (Value).

---

## ğŸ“ˆ Visualizing the Strategy Shift

The scatter plot below reveals exactly *why* the optimization engine outperforms the baseline.

<img width="405" height="263" alt="image" src="https://github.com/user-attachments/assets/f0077663-3732-449c-8384-03e174a8d9fb" />

*Figure 1: Optimization engine (green) identifies high-value accounts that naive risk-based sorting (red) misses*

**What this shows:**
* **X-axis:** Probability of Default (Risk).
* **Y-axis:** Outstanding Balance (Value).
* **Red Dots (Naive Strategy):** The baseline strategy clusters on the far right. It captures high risk, but often ignores value (e.g., chasing a \$100 debt with 90% risk).
* **Green X's (Optimized Strategy):** The engine identifies **"Whales"**â€”accounts with moderate risk (30-50%) but high balances (\$10k+). These are the opportunities that drive the 27% revenue uplift.

---

## ğŸ”¬ Model Performance

### Risk Model (Random Forest)
* **ROC-AUC:** 0.84 (Strong discrimination between payers and defaulters).
* **Brier Score:** 0.16 (Low score indicates well-calibrated probabilities).
* **Calibration:** Applied **Isotonic Regression** to ensure the predicted probabilities are mathematically accurate for expected value calculations.

### Optimization Performance
* **Solve Time:** <2 seconds for 10,000 accounts.
* **Optimality:** 100% (Guaranteed optimal solution via Linear Programming).

---


## ğŸ’» How to Run This Project

### Prerequisites
```bash
pip install -r requirements.txt
```

### 1. Generate Data
Create the synthetic dataset:
```bash
python generate_data.py
```

### 2. Train Models
Train the Risk (PD) and Severity (LGD) models:
```bash
python train_model.py
```

### 3. Run Optimization
Execute the Linear Programming solver to see the results in your terminal:
```bash
python optimize.py
```

### 4. Launch Dashboard
Start the interactive web app:
```bash
streamlit run app.py
```

## ğŸ’¼ Real-World Applications

This optimization framework generalizes to any scenario with:
1. âœ… Limited Resources (call center capacity, sales rep bandwidth)
2. âœ… Uncertain Outcomes (will customer pay? will lead convert?)
3. âœ… Variable Payoffs (different account values)

**Industry Use Cases:**
- **Collections & Recovery:** Credit card delinquency, loan workouts, 
  medical debt collections
- **Customer Retention:** Churn prevention campaigns, win-back offers, 
  targeted retention
- **Sales Optimization:** Lead prioritization under quota constraints, 
  territory assignment
- **Healthcare:** Patient outreach for preventive care under limited 
  clinical hours

**Key Insight:** Traditional strategies optimize for risk alone. 
This engine optimizes for expected business value under real-world 
constraints.

---

## âš ï¸ Limitations & Future Work

**Current Scope:**
- Synthetic dataset (real-world validation pending)
- Fixed LGD assumption (60% for all accounts)
- Static intervention effect (30% success rate)
- Single-period optimization (today only, not multi-day)

**Future Enhancements:**
1. **Dynamic LGD Modeling:** Segment-specific recovery rates 
   (enterprise vs. SME vs. individual)
2. **Multi-Period Optimization:** Optimize over next 7-30 days 
   with contact frequency constraints
3. **Fairness Constraints:** Ensure demographic/geographic balance 
   in outreach
4. **A/B Testing Framework:** Real-world validation of intervention 
   effects
5. **Reinforcement Learning:** Learn optimal intervention timing 
   from historical outcomes
6. **Production API:** REST endpoint for real-time scoring and 
   prioritization

---

## ğŸ“š Technical Stack

**Data & Modeling:**
- Python 3.9+
- Scikit-learn (Random Forest, Isotonic Regression)
- XGBoost (Gradient Boosting)
- Pandas, NumPy (Data manipulation)

**Optimization:**
- PuLP (Linear Programming interface)
- CBC Solver (Open-source LP solver)

**Visualization & Deployment:**
- Streamlit (Interactive dashboard)
- Matplotlib, Seaborn (Charts)

## ğŸ“„ License

This project is for educational and portfolio purposes.

---

## ğŸ“§ Contact

**Anirudh Kumar Pentapati**
- LinkedIn: [linkedin.com/in/anirudhkumar98](https://linkedin.com/in/anirudhkumar98)
- Email: anirudhkumarpentapati@gmail.com
- Location: Hyderabad, India

*Open to opportunities in Data Science, Risk Analytics, and Operations Research roles.*

---

**Development:**
- Git (Version control)
- Jupyter (Exploratory analysis)
